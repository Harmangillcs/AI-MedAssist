# ğŸ“Š AI-MedAssist: End-to-End Medical Chatbot Using LLaMA 2

AI-MedAssist is a local, privacy-preserving **Generative AI-powered chatbot** built using the **LLaMA-2 model**, capable of answering medical queries. The project uses vector search, LangChain, FAISS, and Flask to create a real-time interactive experience.

---

## ğŸš€ Features

* âœ… Locally hosted LLaMA-2 model (no OpenAI/GPT API required)
* ğŸ“„ Answers based on your custom PDF medical data
* ğŸ” Fast document search using FAISS
* ğŸŒ Simple web interface using Flask
* ğŸ§  Uses LangChain for chaining and prompt templating
* ğŸ–¼ï¸ Clean user interface using HTML & CSS

---

## ğŸ“ Folder Structure

```
â”œâ”€â”€ app.py
â”œâ”€â”€ store_index.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ model/
â”‚   â””â”€â”€ llama-2-7b-chat.ggmlv3.q4_0.bin
â”œâ”€â”€ faiss_index/
â”‚   â”œâ”€â”€ index.faiss
â”‚   â””â”€â”€ index.pkl
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ Doctor_img.webp
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ Index.html
â”œâ”€â”€ data/
â”‚   â””â”€â”€ (your medical PDFs)
â””â”€â”€ src/
    â”œâ”€â”€ helper.py
    â””â”€â”€ prompt.py
```

---

## ğŸ› ï¸ How to Run the Project

### âœ… Step 1: Clone the repository

```bash
git clone https://github.com/Harmangillcs/AI-MedAssist.git
cd AI-MedAssist
```

### âœ… Step 2: Create and activate a virtual environment

```bash
py -3.10 -m venv mchatbot
mchatbot\Scripts\activate  # For Windows
```

### âœ… Step 3: Install Python dependencies

```bash
pip install -r requirements.txt
```

### âœ… Step 4: Download and place the model manually

Download the model file from Hugging Face:
ğŸ”— [https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML](https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML)

Choose the file:

```
llama-2-7b-chat.ggmlv3.q4_0.bin
```

Place it inside the `model/` folder:

```
model/llama-2-7b-chat.ggmlv3.q4_0.bin
```

### âœ… Step 5: Prepare the FAISS index (run once)

Ensure your medical PDFs are in the `data/` folder, then run:

```bash
python store_index.py
```

This script loads your PDFs, creates embeddings, and saves the FAISS index.

### âœ… Step 6: Start the chatbot

```bash
python app.py
```

Then open your browser and go to:
ğŸ”— [http://127.0.0.1:5000](http://127.0.0.1:5000)

---

## ğŸ” .gitignore Recommendation

To avoid pushing large files like models and Python environments:

```
model/
mchatbot/
__pycache__/
*.pyc
*.pkl
*.bin
*.log
.env
```

---

## ğŸ” Notes

* This chatbot is for **educational use only**. Not for real medical use.
* You can try **TinyLLaMA** for faster local testing.
* If GitHub blocks push due to large files:

  * Use [Git LFS](https://git-lfs.github.com)
  * Or remove files using `.gitignore` and `git rm --cached`

---

## ğŸ“œ License

This project is for **non-commercial**, academic, and research purposes only.
Check LLaMA license terms from Meta/Hugging Face separately.

---

## ğŸ‘©â€ğŸ’¼ Author

**Harman Gill**

GitHub: [https://github.com/Harmangillcs](https://github.com/Harmangillcs)

Feel free to connect or fork the repo if you're working on similar ideas!
