{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b417682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "import faiss\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab617b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    loader = DirectoryLoader(data_path, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4718d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = r\"G:\\End to End Medical Chatbot Using LLama2\\data\"\n",
    "#extracted_data = load_data(data_path)\n",
    "extracted_data=load_data(\"data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78475425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "545579bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the  text chunks \n",
    "\n",
    "def text_split(extracted_data):\n",
    "    text_splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=20)\n",
    "    split_chunks=text_splitter.split_documents(extracted_data)\n",
    "    return split_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "146abba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks=text_split(extracted_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e60aecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5699"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "106a27a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vector embedding model\n",
    "def embedding_model():\n",
    "    embeddings=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "284d0a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=embedding_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8d5c76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384\n"
     ]
    }
   ],
   "source": [
    "#Test Embedding model\n",
    "query_res=embedding.embed_query(\"Hello world\")\n",
    "print(len(query_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12176bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Vector store\n",
    "vectordb=FAISS.from_texts([t.page_content for t in text_chunks],embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba7c7886",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain.vectorstores.faiss.FAISS at 0x255bf8bc550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7729fb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the index and extract it \n",
    "vectordb.save_local(\"faiss_index\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82b2f793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result [Document(page_content='Causes & symptoms\\nOf all the causes of allergies , pollen is one of the\\nmost widespread. Trees, weeds, and grasses produce\\npollen in large amounts for seed production. These pol-\\nlens are dispersed by the wind, and many never reach the\\nintended targets. Instead, they are inhaled through the\\nnose and throat. Different plants release their pollen at\\ndifferent times of the year, so the timing of hay fever\\nsymptoms varies from person to person, depending on\\nwhich plants provoke a response.', metadata={}), Document(page_content='Allergen —A substance capable of producing an\\nimmediate type of hypersensitivity , or allergy .\\nWheal —A smooth, slightly elevated area on the\\nbody surface, which is redder or paler than the\\nsurrounding skin.\\nGEAM - D to K  10/11/04 3:25 PM  Page 970', metadata={}), Document(page_content='harmless substances, the resulting reaction is called an\\nallergy . An attack of hives is set off when such a sub-\\nstance, called an allergen, is ingested, inhaled, or other-\\nwise contacted. It interacts with immune cells called\\nmast cells, which reside in the skin, airways, and diges-\\ntive system. When mast cells encounter an allergen, they\\nrelease histamine and other chemicals, both locally and\\ninto the bloodstream. These chemicals cause blood ves-', metadata={})]\n"
     ]
    }
   ],
   "source": [
    "vectordb = FAISS.load_local(\"faiss_index\", embeddings=embedding)\n",
    "query=\"What are Allergies\"\n",
    "\n",
    "docs=vectordb.similarity_search(query,k=3)\n",
    "print(\"Result\",docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "432e373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Prompt Template\n",
    "\n",
    "prompt_template=\"\"\"\n",
    "Use the following information to answer the user's questions.\n",
    "If you donot know any answer just say that i donot know, donot try to make up an answer.\n",
    "\n",
    "Context:{context}\n",
    "Question:{question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful Answer:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d80f4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT=PromptTemplate(\n",
    "    template=prompt_template,\n",
    "    input_variables=[\"context\",\"question\"]\n",
    ")\n",
    "chain_type_kwargs={\"prompt\": PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f60380a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for CTransformers\n__root__\n  Model path 'model\\llama-2-7b-chat.ggmlv3.q4_0.bin' doesn't exist. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CTransformers\n\u001b[1;32m----> 2\u001b[0m llm\u001b[38;5;241m=\u001b[39m\u001b[43mCTransformers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mllama-2-7b-chat.ggmlv3.q4_0.bin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_new_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mg:\\End to End Medical Chatbot Using LLama2\\mchatbot\\lib\\site-packages\\langchain\\load\\serializable.py:74\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lc_kwargs \u001b[38;5;241m=\u001b[39m kwargs\n",
      "File \u001b[1;32mg:\\End to End Medical Chatbot Using LLama2\\mchatbot\\lib\\site-packages\\pydantic\\main.py:347\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for CTransformers\n__root__\n  Model path 'model\\llama-2-7b-chat.ggmlv3.q4_0.bin' doesn't exist. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from langchain.llms import CTransformers\n",
    "llm=CTransformers(\n",
    "    model=\"model\\llama-2-7b-chat.ggmlv3.q4_0.bin\",\n",
    "    model_type=\"llama\",\n",
    "    config={\"max_new_tokens\": 512,\n",
    "            \"temperature\":0.8}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86090a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa=RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectordb.as_retriever(search_kwargs={'k':2}),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af5c84d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
